{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from XGBoostPackage import xgbClass\n",
    "from CrossValidation2 import CVScore\n",
    "from Stacking import Ensemble, EnsembleClassifier\n",
    "from Stacking2 import Ensemble2, EnsembleClassifier21, EnsembleClassifier22\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('X_train5_200feat.csv').iloc[:,1:]\n",
    "X_test=pd.read_csv('X_test5_200feat.csv').iloc[:,1:]\n",
    "y_train=pd.read_csv('y_train.csv')['interest_level'].ravel()#low0, medium1, high2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# index=[True]*len(X_train)\n",
    "# for i in [0,1,2]:\n",
    "#     index=index&~pd.isnull(X_train.iloc[:,i])\n",
    "# X_train=X_train[index]\n",
    "# y_train=y_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49352, 245), (49352,), (74659, 245))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_folds=3\n",
    "base_models=[RandomForestClassifier(n_estimators=500, max_features='auto', max_depth=25),\\\n",
    "            xgbClass(objective='multi:softprob', eva_metric=\"mlogloss\", colsample_bytree=.7, eta=.02, \\\n",
    "                      max_depth=6, min_child_weight=1, num_class=3, subsample=.7, silent=1, seed=321,\n",
    "                     num_rounds=2000), \n",
    "            ExtraTreesClassifier(n_estimators=500, max_features='auto', max_depth=25)]\n",
    "ensembleObj=EnsembleClassifier22(n_folds=n_folds, n_class=3, \n",
    "                                 stacker=xgbClass(objective='multi:softprob', \\\n",
    "                                                                         eva_metric=\"mlogloss\", \\\n",
    "                                           colsample_bytree=.7, eta=.1, max_depth=6, min_child_weight=1, \\\n",
    "                                           num_class=3, subsample=.7, silent=1), \\\n",
    "                     base_models=base_models, random_state=17)#,\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startig training model 0, training set 0\n",
      "startig predicting model 0, training set 0\n",
      "startig training model 0, training set 1\n",
      "startig predicting model 0, training set 1\n",
      "startig training model 0, training set 2\n",
      "startig predicting model 0, training set 2\n",
      "startig training model 1, training set 0\n",
      "startig predicting model 1, training set 0\n",
      "startig training model 1, training set 1\n",
      "startig predicting model 1, training set 1\n",
      "startig training model 1, training set 2\n",
      "startig predicting model 1, training set 2\n",
      "startig training model 2, training set 0\n",
      "startig predicting model 2, training set 0\n",
      "startig training model 2, training set 1\n",
      "startig predicting model 2, training set 1\n",
      "startig training model 2, training set 2\n",
      "startig predicting model 2, training set 2\n"
     ]
    }
   ],
   "source": [
    "pred=ensembleObj.fit_predict_proba(T=X_test, X=X_train, y=y_train)\n",
    "#pred=ensembleObj.fit_predict(T=X_test, X=X_train, y=y_train)\n",
    "del ensembleObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_fit, X_val, y_fit, y_val=train_test_split(X_train[:5000], y_train[:5000], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "base_models=[RandomForestClassifier(n_estimators=1000, max_features='auto', max_depth=25),\\\n",
    "            xgbClass(objective='multi:softprob', eva_metric=\"mlogloss\", colsample_bytree=.7, eta=.02, \\\n",
    "                      max_depth=6, min_child_weight=1, num_class=3, subsample=.7, silent=1, seed=321,\n",
    "                     num_rounds=2000), \n",
    "            ExtraTreesClassifier(n_estimators=500, max_features='auto', max_depth=25)]\n",
    "ensembleObj=EnsembleClassifier2(n_folds=n_folds, n_class=3, stacker=xgbClass(objective='multi:softprob', \\\n",
    "                                                                         eva_metric=\"mlogloss\", \\\n",
    "                                           colsample_bytree=.7, eta=.1, max_depth=6, min_child_weight=1, \\\n",
    "                                           num_class=3, subsample=.7, silent=1), \\\n",
    "                     base_models=base_models, random_state=17)#,\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startig training model 0, training set 0\n",
      "startig predicting model 0, training set 0\n",
      "startig training model 0, training set 1\n",
      "startig predicting model 0, training set 1\n",
      "startig training model 0, training set 2\n",
      "startig predicting model 0, training set 2\n",
      "startig training model 0, training set 3\n",
      "startig predicting model 0, training set 3\n",
      "startig training model 0, training set 4\n",
      "startig predicting model 0, training set 4\n",
      "startig training model 1, training set 0\n",
      "startig predicting model 1, training set 0\n",
      "startig training model 1, training set 1\n",
      "startig predicting model 1, training set 1\n",
      "startig training model 1, training set 2\n",
      "startig predicting model 1, training set 2\n",
      "startig training model 1, training set 3\n",
      "startig predicting model 1, training set 3\n",
      "startig training model 1, training set 4\n",
      "startig predicting model 1, training set 4\n",
      "startig training model 2, training set 0\n",
      "startig predicting model 2, training set 0\n",
      "startig training model 2, training set 1\n",
      "startig predicting model 2, training set 1\n",
      "startig training model 2, training set 2\n",
      "startig predicting model 2, training set 2\n",
      "startig training model 2, training set 3\n",
      "startig predicting model 2, training set 3\n",
      "startig training model 2, training set 4\n",
      "startig predicting model 2, training set 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75284108823333307"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=ensembleObj.fit_predict_proba(T=X_val, X=X_fit, y=y_fit)\n",
    "log_loss(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74512806818289856"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=xgbClass(objective='multi:softprob', eva_metric=\"mlogloss\", colsample_bytree=.7, eta=.02, \\\n",
    "                      max_depth=6, min_child_weight=1, num_class=3, subsample=.7, silent=1, seed=321,\n",
    "                     num_rounds=2000)\n",
    "model.fit(X_fit, y_fit)\n",
    "y_pred=model.predict_proba(X_val)\n",
    "log_loss(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startig training model 0, training set 0\n",
      "startig training model 0, training set 1\n",
      "startig training model 0, training set 2\n",
      "startig training model 0, training set 3\n",
      "startig training model 0, training set 4\n",
      "startig training model 1, training set 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-35d1f964f878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             [ExtraTreesClassifier(n_estimators=500, max_features='auto', max_depth=25) for i in np.arange(n_folds)]]\n\u001b[1;32m      6\u001b[0m \u001b[0mensembleObj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEnsembleClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgbClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi:softprob'\u001b[0m\u001b[0;34m,\u001b[0m                                                                          \u001b[0meva_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mlogloss\"\u001b[0m\u001b[0;34m,\u001b[0m                                            \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m                                            \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0mbase_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_TimeSeries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mensembleObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jingguo/Desktop/KaggleCompetition/connectModels/Stacking.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mX_CVholdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# y_CVholdout = y_train[test_idx]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_CVtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_CVtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_CVholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Desktop/KaggleCompetition/connectModels/XGBoostPackage.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Library/Python/2.7/lib/python/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Library/Python/2.7/lib/python/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Library/Python/2.7/lib/python/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_folds=5\n",
    "base_models=[[RandomForestClassifier(n_estimators=1000, max_features='auto', max_depth=25) for i in np.arange(n_folds)],\\\n",
    "            [xgbClass(objective='multi:softprob', eva_metric=\"mlogloss\", colsample_bytree=.7, eta=.02, \\\n",
    "                      max_depth=6, min_child_weight=1, num_class=3, subsample=.7, silent=1, seed=321,\n",
    "                     num_rounds=2000) \\\n",
    "             for i in np.arange(n_folds)], \n",
    "            [ExtraTreesClassifier(n_estimators=500, max_features='auto', max_depth=25) for i in np.arange(n_folds)]]\n",
    "ensembleObj=EnsembleClassifier(n_folds=n_folds, n_class=3, stacker=xgbClass(objective='multi:softprob', \\\n",
    "                                                                         eva_metric=\"mlogloss\", \\\n",
    "                                           colsample_bytree=.7, eta=.1, max_depth=6, min_child_weight=1, \\\n",
    "                                           num_class=3, subsample=.7, silent=1), \\\n",
    "                     base_models=base_models, is_TimeSeries=False, random_state=17)#,\\\n",
    "ensembleObj.fit(X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred=ensembleObj.predict_proba(X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "base_models=[[RandomForestClassifier(n_estimators=1000, max_features='auto', max_depth=25) for i in np.arange(n_folds)],\\\n",
    "            [xgbClass(objective='multi:softprob', eva_metric=\"mlogloss\", colsample_bytree=.7, eta=.02, \\\n",
    "                      max_depth=6, min_child_weight=1, num_class=3, subsample=.7, silent=1, seed=321,\n",
    "                     num_rounds=2000) \\\n",
    "             for i in np.arange(n_folds)], \n",
    "            [ExtraTreesClassifier(n_estimators=500, max_features='auto', max_depth=25) for i in np.arange(n_folds)]]\n",
    "ensembleObj=EnsembleClassifier(n_folds=n_folds, n_class=3, stacker=xgbClass(objective='multi:softprob', \\\n",
    "                                                                         eva_metric=\"mlogloss\", \\\n",
    "                                           colsample_bytree=.7, eta=.1, max_depth=6, min_child_weight=1, \\\n",
    "                                           num_class=3, subsample=.7, silent=1), \\\n",
    "                     base_models=base_models, is_TimeSeries=False, random_state=17)#,\\\n",
    "ensembleObj.fit(X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(pred)\n",
    "out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "out_df[\"listing_id\"] = pd.read_json(\"../input/test.json\").listing_id.values\n",
    "out_df.to_csv(\"apr25_1_Stack.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
