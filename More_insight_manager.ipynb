{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Hello there, everyone.  I did a brief analysis on the \"managers\" since at first glance the average \"interest level\" seemed to differ substantially from one to another . \n\nAnyway, let me know what you think about it and like this notebook if you enjoyed reading it (it's my 1st one, be nice :D)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# let's load the usual packages first\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "... and get the data...",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_df = pd.read_json('../input/train.json')\ntest_df = pd.read_json('../input/test.json')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First of all, let's see how many different managers we have on both datasets.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "man_train_list = train_df.manager_id.unique()\nman_test_list = test_df.manager_id.unique()\nprint(\"Train: {0}\".format(len(man_train_list)))\nprint(\"Test: {0}\".format(len(man_test_list)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "There are more managers in the test dataset, which also features more records.\n\nLet's create a dataframe with all the train and test managers, including the number of entries they are responsible for.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "temp1 = train_df.groupby('manager_id').count().iloc[:,-1]\ntemp2 = test_df.groupby('manager_id').count().iloc[:,-1]\ndf_managers = pd.concat([temp1,temp2], axis = 1, join = 'outer')\ndf_managers.columns = ['train_count','test_count']\nprint(df_managers.head(20))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Some managers have entries only in one of the two datasets. But as we will see later, these managers have only very few entries.\n\nIndeed, a minority of managers are responsible for most of the entries of both dataset",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df_managers.sort_values(by = 'train_count', ascending = False).head(10))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This is more clear if one looks at the plots for the cumulative distributions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fig, axes = plt.subplots(1,2, figsize = (12,5))\ntemp = df_managers['train_count'].dropna().sort_values(ascending = False).reset_index(drop = True)\naxes[0].plot(temp.index+1, temp.cumsum()/temp.sum())\naxes[0].set_title('cumulative train_count')\n\ntemp = df_managers['test_count'].dropna().sort_values(ascending = False).reset_index(drop = True)\naxes[1].plot(temp.index+1, temp.cumsum()/temp.sum())\naxes[1].set_title('cumulative test_count')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The Pareto principle, i.e. the 80/20 rule, seems to apply here. As 20% of the managers are roughly responsible for roughly 80% of the entries.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ix20 = int(len(df_managers['train_count'].dropna())*0.2)\nprint(\"TRAIN: 20% of managers ({0}) responsible for {1:2.2f}% of entries\".format(ix20,df_managers['train_count'].sort_values(ascending = False).cumsum().iloc[ix20]/df_managers['train_count'].sum()*100))\n\nix20 = int(len(df_managers['test_count'].dropna())*0.2)\nprint(\"TEST: 20% of managers ({0}) responsible for {1:2.2f}% of entries\".format(ix20, df_managers['test_count'].sort_values(ascending = False).cumsum().iloc[ix20]/df_managers['test_count'].sum()*100))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "As mentioned before, fortunately, these top contributors are the same for both datasets. The managers featuring in only one of the two datasets usually have very few entries.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "man_not_in_test = set(man_train_list) - set(man_test_list)\nman_not_in_train = set(man_test_list) - set(man_train_list)\n\nprint(\"{} managers are featured in train.json but not in test.json\".format(len(man_not_in_test)))\nprint(\"{} managers are featured in test.json but not in train.json\".format(len(man_not_in_train)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df_managers.loc[list(man_not_in_test)]['train_count'].describe())\nprint(df_managers.loc[list(man_not_in_train)]['test_count'].describe())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Besides, it looks like there is a strong correlation between the number of entries of the contributors in both datasets.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_managers.sort_values(by = 'train_count', ascending = False).head(1000).corr()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_managers.sort_values(by = 'train_count', ascending = False).head(100).plot.scatter(x = 'train_count', y = 'test_count')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now let's focus on the training dataset and on the \"interest_level\" of its top 100 contributors.\nThese folks account for a whopping 35% of the entries. The 1st alone for over 5% of them! That's quite a lot. \n\nAccording to the discussion above, similar figures are expected for the test dataset.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "temp = df_managers['train_count'].sort_values(ascending = False).head(100)\ntemp = pd.concat([temp,temp.cumsum()/df_managers['train_count'].sum()*100], axis = 1).reset_index()\ntemp.columns = ['manager_id','count','percentage']\nprint(temp)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's isolate the entries relative to these 100 managers with the \"interest_level\" column as well. We create dummies from this latter column as they are easier to work with.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "man_list = df_managers['train_count'].sort_values(ascending = False).head(100).index\nixes = train_df.manager_id.isin(man_list)\ndf100 = train_df[ixes][['manager_id','interest_level']]\ninterest_dummies = pd.get_dummies(df100.interest_level)\ndf100 = pd.concat([df100,interest_dummies[['low','medium','high']]], axis = 1).drop('interest_level', axis = 1)\n\nprint(\"The top100 contributors account for {} entries\\n\".format(len(df100)))\n\nprint(df100.head(10))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Before continuing, let's give them some fake identities based on the most common first and last names in the US.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import itertools\n\n# 50 most common surnames in the 90s (http://surnames.behindthename.com/top/lists/united-states/1990)\nlast_names = ['Smith', 'Johnson', 'Williams', 'Jones', 'Brown', 'Davis', 'Miller', 'Wilson', 'Moore', \n 'Taylor', 'Anderson', 'Thomas', 'Jackson', 'White', 'Harris', 'Martin', 'Thompson', 'Garcia', \n 'Martinez', 'Robinson', 'Clark', 'Rodriguez', 'Lewis', 'Lee', 'Walker', 'Hall', 'Allen', 'Young',\n 'Hernandez', 'King', 'Wright', 'Lopez', 'Hill', 'Scott', 'Green', 'Adams', 'Baker', 'Gonzalez', 'Nelson', \n 'Carter', 'Mitchell', 'Perez', 'Roberts', 'Turner', 'Phillips', 'Campbell', 'Parker', 'Evans', 'Edwards', 'Collins']\n\n# 10 most common first names for females and males (names.mongabay.com) \nfirst_names = ['Mary',  'Patricia',  'Linda',  'Barbara',  'Elizabeth',  \n               'Jennifer',  'Maria',  'Susan',  'Margaret',  'Dorothy',\n               'James', 'John', 'Robert', 'Michael', 'William', 'David',\n               'Richard', 'Charles', 'Joseph', 'Thomas']\n\nnames = [first + ' ' + last for first,last in (itertools.product(first_names, last_names))]\n\n# shuffle them\nnp.random.seed(12345)\nnp.random.shuffle(names)\n\ndictionary = dict(zip(man_list, names))\ndf100.loc[df100.manager_id.isin(dictionary), 'manager_id' ] = df100['manager_id'].map(dictionary)\nprint(df100.head())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# see if the name coincides\nprint(names[:10])\nprint(df100.groupby('manager_id').count().sort_values(by = 'low', ascending = False).head(10))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Splendid... we have their names now, so let's proceed and compute their average performances in terms of \"interest level\" so we can spot who's a pro and who's not. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "gby = pd.concat([df100.groupby('manager_id').mean(),df100.groupby('manager_id').count()], axis = 1).iloc[:,:-2]\ngby.columns = ['low','medium','high','count']\ngby.sort_values(by = 'count', ascending = False).head(10)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Their performances seem very different, even for people with similar number of entries.\n\nIndeed they are..",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "gby.sort_values(by = 'count', ascending = False).drop('count', axis = 1).plot(kind = 'bar', stacked = True, figsize = (15,5))\nplt.figure()\ngby.sort_values(by = 'count', ascending = False)['count'].plot(kind = 'bar', figsize = (15,5))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "I think this high diversity should be accounted for when building our predictive model! \n\nIt would be interesting to rank the managers based on their intereset levels. For instance, we could compute their \"skill\" by assigning 0 points for \"lows\", 1 for \"mediums\" and 2 for \"highs\". Since they have different number of entries, let's quickly do so by multiplying the average results.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "gby['skill'] = gby['medium']*1 + gby['high']*2 \n\nprint(\"Top performers\")\nprint(gby.sort_values(by = 'skill', ascending = False).reset_index().head())\nprint(\"\\nWorst performers\")\nprint(gby.sort_values(by = 'skill', ascending = False).reset_index().tail())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Dorothy Turner and Dorothy Lopez are rocking it! Poor Dorothy Martinez instead should consider moving to another industry... 402 entries, all of them uninspiring (btw I did not pick the random seed to have all the Dorothies here...).\n\nI won't go deeper to try to explain why these performances are so different. It seems though like most of the managers do a poor job (I am sure it ain't their fault, is just that the properties they handle are not that cool after all...).\n\nCheers!\n\np.s.: I did a similar analysis on \"building_id\" here --> https://www.kaggle.com/den3b81/two-sigma-connect-rental-listing-inquiries/some-insights-on-building-id",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "gby.skill.plot(kind = 'hist')\nprint(gby.mean())",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}