{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
<<<<<<< HEAD
    "collapsed": true,
    "deletable": true,
    "editable": true
=======
    "collapsed": true
>>>>>>> 1459e333d7e01405f6fde679f78fedeb847bb9b2
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import kagglegym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from time import time\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "\n",
    "\n",
    "env = kagglegym.make()\n",
    "o = env.reset()\n",
    "#o.train = o.train[:1000]\n",
    "excl = [env.ID_COL_NAME, env.SAMPLE_COL_NAME, env.TARGET_COL_NAME, env.TIME_COL_NAME]\n",
    "col = [c for c in o.train.columns if c not in excl]\n",
    "\n",
    "#train = pd.read_hdf(r'C:\\Users\\jiguo\\Desktop\\KProject\\input\\train.h5')\n",
    "O = pd.read_hdf('../input/train.h5')\n",
    "d_mean= O[col].median(axis=0)\n",
    "ymean_dict = dict(o.train.groupby([\"id\"])[\"y\"].median())\n",
    "\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "#train for trees\n",
    "X_train = o.train[col]\n",
    "y_train=o.train.y\n",
    "# n = train.isnull().sum(axis=1)\n",
    "# for c in train.columns:\n",
    "#     train[c + '_nan_'] = pd.isnull(train[c])\n",
    "#     d_mean[c + '_nan_'] = 0\n",
    "# train = train.fillna(d_mean)\n",
    "# train['znull'] = n\n",
    "# n = []\n",
    "\n",
    "def NAOperation(trainInput, d_mean):\n",
    "    train=trainInput.copy()\n",
    "    n = train.isnull().sum(axis=1)\n",
    "    for c in train.columns:\n",
    "        train[c + '_nan_'] = pd.isnull(train[c])\n",
    "        d_mean[c + '_nan_'] = 0\n",
    "    train = train.fillna(d_mean)\n",
    "    train['znull'] = n\n",
    "    n = []\n",
    "    return train\n",
    "\n",
    "class LR_tech():\n",
    "    def __init__(self, d_mean, colLR=['technical_20'], low_y_cut=-0.085, high_y_cut=0.075, n_jobs=-1):\n",
    "        self.low_y_cut = low_y_cut\n",
    "        self.high_y_cut = high_y_cut\n",
    "        self.model=LinearRegression(n_jobs=n_jobs)\n",
    "        self.d_mean=d_mean\n",
    "        #self.col=col\n",
    "        self.colLR=colLR\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        #d_mean= x_train.median(axis=0)\n",
    "        #x_train=x_train.fillna(d_mean)\n",
    "        #x_train = x_train[self.col]\n",
    "        y_is_above_cut = (y_train > self.high_y_cut)\n",
    "        y_is_below_cut = (y_train < self.low_y_cut)\n",
    "        y_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)\n",
    "        self.model.fit(np.array(X_train.loc[y_is_within_cut, self.colLR].fillna(self.d_mean).values).\\\n",
    "                                      reshape(-1,len(self.colLR)), y_train.loc[y_is_within_cut])\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(np.array(X_test[self.colLR].fillna(self.d_mean).values).\\\n",
    "                                  reshape(-1,len(self.colLR))).clip(self.low_y_cut, self.high_y_cut)\n",
    "\n",
    "\n",
    "class RTR(object):\n",
    "    def __init__(self, d_mean, n_estimators=40, max_features='auto', max_depth=4, n_jobs=-1, random_state=17, verbose=0):\n",
    "#         self.objective=objective\n",
    "#         self.colsample_bytree=colsample_bytree\n",
    "#         self.subsample=subsample\n",
    "#         self.min_child_weight=min_child_weight\n",
    "#         self.base_score=base_score\n",
    "        self.d_mean=d_mean\n",
    "        self.model=ExtraTreesRegressor(n_estimators=n_estimators, max_features='auto', \\\n",
    "                                       max_depth=max_depth, n_jobs=n_jobs, random_state=random_state, \\\n",
    "                                   verbose=verbose)\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(NAOperation(X_train, self.d_mean), y_train)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(NAOperation(X_test, self.d_mean))\n",
    "\n",
    "class XGBoost(object):\n",
    "    def __init__(self, d_mean, objective='reg:linear', colsample_bytree=.8, \\\n",
    "                 subsample=.9, min_child_weight=1000, base_score=.5):\n",
    "        self.d_mean=d_mean\n",
    "        self.model=xgb.XGBRegressor(objective=objective, colsample_bytree=colsample_bytree, \\\n",
    "                        subsample=subsample, min_child_weight=min_child_weight, base_score=base_score)\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train.fillna(d_mean), y_train)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test.fillna(d_mean))\n",
    "\n",
    "\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_folds, stacker, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "        self.S_train=[]\n",
    "        self.S_test=[]\n",
    "        self_folds=[]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #X = np.array(X)\n",
    "        #y = np.array(y)\n",
    "        self.folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=False, random_state=17))\n",
    "        self.S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            for j, (train_idx, test_idx) in enumerate(self.folds):\n",
    "                X_train = X.iloc[train_idx]\n",
    "                y_train = y.iloc[train_idx]\n",
    "                X_holdout = X.iloc[test_idx]\n",
    "                # y_holdout = y[test_idx]\n",
    "                clf[j].fit(X_train, y_train)\n",
    "                y_pred = clf[j].predict(X_holdout)[:]\n",
    "                self.S_train[test_idx, i] = y_pred\n",
    "        self.stacker.fit(self.S_train, y)\n",
    "        \n",
    "    def predict(self, T):       \n",
    "        #T = np.array(T)       \n",
    "        self.S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            S_test_i = np.zeros((T.shape[0], len(self.folds)))\n",
    "            for j in range(len(self.folds)):\n",
    "                S_test_i[:, j] = clf[j].predict(T)[:]\n",
    "            self.S_test[:, i] = S_test_i.mean(1)\n",
    "#             self.S_test[:,i]=[sum(map(lambda x: (x.predict(T))[0],clf))/self.n_folds]\n",
    "        y_pred = self.stacker.predict(self.S_test)[:]\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "start=time()\n",
    "\n",
    "colLR=['technical_20']\n",
    "n_folds = 2\n",
    "ensembleObj=Ensemble(n_folds=n_folds, stacker=LinearRegression(fit_intercept=False, n_jobs=-1), \\\n",
    "base_models=[[RTR(d_mean=d_mean, n_estimators=50, max_features='auto',\\\n",
    "max_depth=4, n_jobs=-1, random_state=17, verbose=0) for i in range(n_folds)], \\\n",
    "[LR_tech(d_mean=d_mean, colLR=colLR, low_y_cut=-0.075, high_y_cut=0.085, n_jobs=-1) for i in range(n_folds)], \\\n",
    "[XGBoost(d_mean=d_mean, objective='reg:linear', colsample_bytree=.8, subsample=.8, min_child_weight=1000,\\\n",
    "base_score=.5) for i in range(n_folds)]])\n",
    "ensembleObj.fit(X=X_train, y=y_train) \n",
    "end = time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "print(ensembleObj.stacker.coef_)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "start=time()\n",
    "\n",
    "coeff1=.975\n",
    "while True:\n",
    "    test = o.features[col]\n",
    "#     n = test.isnull().sum(axis=1)\n",
    "    # for c in test.columns:\n",
    "    #     test[c + '_nan_'] = pd.isnull(test[c])\n",
    "#     test = test.fillna(d_mean)\n",
    "#     test['znull'] = n\n",
    "    pred = o.target\n",
    "    pred['y'] = ensembleObj.predict(T=test)\n",
    "    pred['y'] = pred.apply(lambda r: coeff1 * r['y'] +(1-coeff1) * ymean_dict[r['id']] if r['id'] in ymean_dict else r['y'], axis = 1)\n",
    "    pred['y'] = [float(format(x, '.6f')) for x in pred['y']]\n",
    "    o, reward, done, info = env.step(pred)\n",
    "    if done:\n",
    "        print(\"el fin ...\", info[\"public_score\"])\n",
    "        break\n",
    "    if o.features.timestamp[0] % 100 == 0:\n",
    "        print(reward)\n",
    "        \n",
    "end = time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
<<<<<<< HEAD
   "version": "2.7.13"
=======
   "version": "2.7.11"
>>>>>>> 1459e333d7e01405f6fde679f78fedeb847bb9b2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
