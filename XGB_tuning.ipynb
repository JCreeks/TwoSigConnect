{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems the current [high scoring script][1] is written in R using H2O. So let us do one in python using XGBoost. \n",
    "\n",
    "Thanks to [this script][2] for feature engineering ideas. \n",
    "\n",
    "We shall start with importing the necessary modules\n",
    "\n",
    "\n",
    "  [1]: https://www.kaggle.com/gospursgo/two-sigma-connect-rental-listing-inquiries/h2o-starter-pack/run/835757\n",
    "  [2]: https://www.kaggle.com/aikinogard/two-sigma-connect-rental-listing-inquiries/random-forest-starter-with-numerical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from XGBoostPackage import xgbClass\n",
    "from CrossValidation import CVScore\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('X_train2.csv')\n",
    "X_test=pd.read_csv('X_test2.csv')\n",
    "y_train=pd.read_csv('y_train.csv')['interest_level'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49352, 74), (49352,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train2\n",
    "param_grid = {'eta':[.03, .02, .01], 'num_round':[1500,2000], 'subsample':[.7], 'colsample_bytree':[.6,.7, .8], \\\n",
    "              'max_depth':[5, 6], 'seed':[2017]}\n",
    "for eta in param_grid['eta']:\n",
    "    for subsample in param_grid['subsample']:\n",
    "        for colsample_bytree in param_grid['colsample_bytree']:\n",
    "            for max_depth in param_grid['max_depth']:\n",
    "                for seed in param_grid['seed']:\n",
    "                    for num_rounds in param_grid['num_round']:\n",
    "                        model=xgbClass(colsample_bytree=colsample_bytree, eta=eta, eva_metric='mlogloss', \\\n",
    "                                       subsample=subsample, max_depth=max_depth, seed=seed,\\\n",
    "                                       objective='multi:softprob', num_class=3,num_rounds=num_rounds)\n",
    "                        score=CVScore(model=model, n_splits=3, my_score=log_loss, X_train=X_train[:],\\\n",
    "                                  y_train=y_train[:])\n",
    "                        del model\n",
    "                        print('eta={}, subsample={}, colsample_bytree={}, max_depth={}, seed={}, score={}, num_rounds={}'.\\\n",
    "                          format(eta, subsample, colsample_bytree, max_depth, seed, score, num_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta=0.1, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.540825406417, num_rounds=500\n",
      "eta=0.1, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.545873966542, num_rounds=1000\n",
      "eta=0.1, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.542463619543, num_rounds=500\n",
      "eta=0.1, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.558406046345, num_rounds=1000\n",
      "eta=0.1, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.550243207701, num_rounds=500\n",
      "eta=0.1, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.584102265197, num_rounds=1000\n",
      "eta=0.04, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.546367050983, num_rounds=500\n",
      "eta=0.04, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.539431759275, num_rounds=1000\n",
      "eta=0.04, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.540349950191, num_rounds=500\n",
      "eta=0.04, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.537623777143, num_rounds=1000\n",
      "eta=0.04, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.538286527894, num_rounds=500\n",
      "eta=0.04, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.540531778231, num_rounds=1000\n",
      "eta=0.02, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.560659518668, num_rounds=500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cd68a8781369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_round'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgbClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mlogloss'\u001b[0m\u001b[0;34m,\u001b[0m                                        \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m                                       \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi:softprob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCVScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                  \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                         \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eta={}, subsample={}, colsample_bytree={}, max_depth={}, seed={}, score={}, num_rounds={}'\u001b[0m\u001b[0;34m.\u001b[0m                          \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Desktop/KaggleCompetition/connectModels/CrossValidation.pyc\u001b[0m in \u001b[0;36mCVScore\u001b[0;34m(model, X_train, y_train, n_splits, is_TimeSeries, seed, my_score)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mX_CVholdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0my_CVholdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_CVtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_CVtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmy_score\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_CVholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Desktop/KaggleCompetition/connectModels/XGBoostPackage.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Library/Python/2.7/lib/python/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Library/Python/2.7/lib/python/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingguo/Library/Python/2.7/lib/python/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {'eta':[.1, .04, .02], 'num_round':[500,1000], 'subsample':[.7], 'colsample_bytree':[.7], \\\n",
    "              'max_depth':[4,5, 6], 'seed':[2017]}\n",
    "for eta in param_grid['eta']:\n",
    "    for subsample in param_grid['subsample']:\n",
    "        for colsample_bytree in param_grid['colsample_bytree']:\n",
    "            for max_depth in param_grid['max_depth']:\n",
    "                for seed in param_grid['seed']:\n",
    "                    for num_rounds in param_grid['num_round']:\n",
    "                        model=xgbClass(colsample_bytree=colsample_bytree, eta=eta, eva_metric='mlogloss', \\\n",
    "                                       subsample=subsample, max_depth=max_depth, seed=seed,\\\n",
    "                                       objective='multi:softprob', num_class=3,num_rounds=num_rounds)\n",
    "                        score=CVScore(model=model, n_splits=3, my_score=log_loss, X_train=X_train[:],\\\n",
    "                                  y_train=y_train[:])\n",
    "                        del model\n",
    "                        print('eta={}, subsample={}, colsample_bytree={}, max_depth={}, seed={}, score={}, num_rounds={}'.\\\n",
    "                          format(eta, subsample, colsample_bytree, max_depth, seed, score, num_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta=0.039, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.546705558332, num_rounds=500\n",
      "eta=0.039, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.539388763722, num_rounds=1000\n",
      "eta=0.039, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.540978387466, num_rounds=500\n",
      "eta=0.039, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.537746906981, num_rounds=1000\n",
      "eta=0.039, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.53864647159, num_rounds=500\n",
      "eta=0.039, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.540213157122, num_rounds=1000\n",
      "eta=0.041, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.546068609062, num_rounds=500\n",
      "eta=0.041, subsample=0.7, colsample_bytree=0.7, max_depth=4, seed=2017, score=0.539298954759, num_rounds=1000\n",
      "eta=0.041, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.540337122732, num_rounds=500\n",
      "eta=0.041, subsample=0.7, colsample_bytree=0.7, max_depth=5, seed=2017, score=0.537719722922, num_rounds=1000\n",
      "eta=0.041, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.53868407927, num_rounds=500\n",
      "eta=0.041, subsample=0.7, colsample_bytree=0.7, max_depth=6, seed=2017, score=0.541314099727, num_rounds=1000\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'eta':[.04], 'num_round':[500,1000], 'subsample':[.7], 'colsample_bytree':[.6,.8], \\\n",
    "              'max_depth':[5], 'seed':[2017]}\n",
    "for eta in param_grid['eta']:\n",
    "    for subsample in param_grid['subsample']:\n",
    "        for colsample_bytree in param_grid['colsample_bytree']:\n",
    "            for max_depth in param_grid['max_depth']:\n",
    "                for seed in param_grid['seed']:\n",
    "                    for num_rounds in param_grid['num_round']:\n",
    "                        model=xgbClass(colsample_bytree=colsample_bytree, eta=eta, eva_metric='mlogloss', \\\n",
    "                                       subsample=subsample, max_depth=max_depth, seed=seed,\\\n",
    "                                       objective='multi:softprob', num_class=3,num_rounds=num_rounds)\n",
    "                        score=CVScore(model=model, n_splits=3, my_score=log_loss, X_train=X_train[:],\\\n",
    "                                  y_train=y_train[:])\n",
    "                        del model\n",
    "                        print('eta={}, subsample={}, colsample_bytree={}, max_depth={}, seed={}, score={}, num_rounds={}'.\\\n",
    "                          format(eta, subsample, colsample_bytree, max_depth, seed, score, num_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting...\n",
      "Fitted\n"
     ]
    }
   ],
   "source": [
    "print(\"Start fitting...\")\n",
    "\n",
    "param = {}\n",
    "param['objective'] = 'multi:softprob'\n",
    "param['eta'] = 0.04\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "param['eval_metric'] = \"mlogloss\"\n",
    "param['min_child_weight'] = 1\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree'] = 0.7\n",
    "param['seed'] = 42\n",
    "param['nthread'] = 8\n",
    "num_rounds = 500\n",
    "\n",
    "xgtrain = xgb.DMatrix(X_train[:], label=y_train)\n",
    "clf = xgb.train(param, xgtrain, num_rounds)\n",
    "\n",
    "print(\"Fitted\")\n",
    "\n",
    "def prepare_submission(model):\n",
    "    xgtest = xgb.DMatrix(X_test[:])\n",
    "    preds = model.predict(xgtest)    \n",
    "    sub = pd.DataFrame(data = {'listing_id': X_test['listing_id'].ravel()})\n",
    "    sub['low'] = preds[:, 0]\n",
    "    sub['medium'] = preds[:, 1]\n",
    "    sub['high'] = preds[:, 2]\n",
    "    sub.to_csv(\"Apr14_1.csv\", index = False, header = True)\n",
    "\n",
    "prepare_submission(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imp=pd.DataFrame()#(index=features_to_use)\n",
    "imp['train'] = pd.Series(model.get_score(importance_type='gain'))#, index=features_to_use)\n",
    "imp = imp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEICAYAAAAzydF1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlitObGZmlitObGZmliv/H4zAlU1FZNsBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cd8f850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=imp.sort_values('train').tail(10).plot.barh(title='Feature importances sorted by train', figsize=(7,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
