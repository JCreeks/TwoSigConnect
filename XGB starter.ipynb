{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems the current [high scoring script][1] is written in R using H2O. So let us do one in python using XGBoost. \n",
    "\n",
    "Thanks to [this script][2] for feature engineering ideas. \n",
    "\n",
    "We shall start with importing the necessary modules\n",
    "\n",
    "\n",
    "  [1]: https://www.kaggle.com/gospursgo/two-sigma-connect-rental-listing-inquiries/h2o-starter-pack/run/835757\n",
    "  [2]: https://www.kaggle.com/aikinogard/two-sigma-connect-rental-listing-inquiries/random-forest-starter-with-numerical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from XGBoostPackage import xgbClass\n",
    "from CrossValidation import CVScore\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let us write a custom function to run the xgboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us read the train and test files and store it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../input/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We do not need any pre-processing for numerical features and so create a list with those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let us create some new features from the given features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list #\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\", \"created_month\", \"created_day\", \"listing_id\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have 4 categorical features in our data\n",
    "\n",
    " - display_address\n",
    " - manager_id\n",
    " - building_id\n",
    " - listing_id\n",
    "\n",
    "So let us label encode these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have features column which is a list of string values. So we can first combine all the strings together to get a single string and then apply count vectorizer on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10                                                         \n",
      "10000     Doorman Elevator Fitness_Center Cats_Allowed D...\n",
      "100004    Laundry_In_Building Dishwasher Hardwood_Floors...\n",
      "100007                               Hardwood_Floors No_Fee\n",
      "100013                                              Pre-War\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "print(train_df[\"features\"].head())\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let us stack both the dense and sparse features into a single dataset and also get the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((49352, 217), (74659, 217))\n"
     ]
    }
   ],
   "source": [
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let us do some cross validation to check the scores. \n",
    "\n",
    "Please run it in local to get the cv scores. I am commenting it out here for time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.04062\ttest-mlogloss:1.04178\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:0.988935\ttest-mlogloss:0.991194\n",
      "[2]\ttrain-mlogloss:0.945879\ttest-mlogloss:0.949042\n",
      "[3]\ttrain-mlogloss:0.909602\ttest-mlogloss:0.913573\n",
      "[4]\ttrain-mlogloss:0.877752\ttest-mlogloss:0.882525\n",
      "[5]\ttrain-mlogloss:0.847277\ttest-mlogloss:0.852886\n",
      "[6]\ttrain-mlogloss:0.821612\ttest-mlogloss:0.827856\n",
      "[7]\ttrain-mlogloss:0.797808\ttest-mlogloss:0.805061\n",
      "[8]\ttrain-mlogloss:0.778228\ttest-mlogloss:0.786171\n",
      "[9]\ttrain-mlogloss:0.762093\ttest-mlogloss:0.770583\n",
      "[10]\ttrain-mlogloss:0.745692\ttest-mlogloss:0.75503\n",
      "[11]\ttrain-mlogloss:0.731993\ttest-mlogloss:0.741936\n",
      "[12]\ttrain-mlogloss:0.719194\ttest-mlogloss:0.729753\n",
      "[13]\ttrain-mlogloss:0.707955\ttest-mlogloss:0.719276\n",
      "[14]\ttrain-mlogloss:0.696854\ttest-mlogloss:0.708794\n",
      "[15]\ttrain-mlogloss:0.68545\ttest-mlogloss:0.698564\n",
      "[16]\ttrain-mlogloss:0.677064\ttest-mlogloss:0.690775\n",
      "[17]\ttrain-mlogloss:0.667979\ttest-mlogloss:0.682298\n",
      "[18]\ttrain-mlogloss:0.659607\ttest-mlogloss:0.674805\n",
      "[19]\ttrain-mlogloss:0.653768\ttest-mlogloss:0.669615\n",
      "[20]\ttrain-mlogloss:0.646382\ttest-mlogloss:0.663043\n",
      "[21]\ttrain-mlogloss:0.64068\ttest-mlogloss:0.658047\n",
      "[22]\ttrain-mlogloss:0.634695\ttest-mlogloss:0.653054\n",
      "[23]\ttrain-mlogloss:0.628663\ttest-mlogloss:0.64772\n",
      "[24]\ttrain-mlogloss:0.623841\ttest-mlogloss:0.643707\n",
      "[25]\ttrain-mlogloss:0.618642\ttest-mlogloss:0.639389\n",
      "[26]\ttrain-mlogloss:0.614731\ttest-mlogloss:0.636213\n",
      "[27]\ttrain-mlogloss:0.610874\ttest-mlogloss:0.632922\n",
      "[28]\ttrain-mlogloss:0.606872\ttest-mlogloss:0.62969\n",
      "[29]\ttrain-mlogloss:0.603053\ttest-mlogloss:0.626626\n",
      "[30]\ttrain-mlogloss:0.599604\ttest-mlogloss:0.624024\n",
      "[31]\ttrain-mlogloss:0.596799\ttest-mlogloss:0.621801\n",
      "[32]\ttrain-mlogloss:0.593019\ttest-mlogloss:0.618769\n",
      "[33]\ttrain-mlogloss:0.590741\ttest-mlogloss:0.617124\n",
      "[34]\ttrain-mlogloss:0.587593\ttest-mlogloss:0.61462\n",
      "[35]\ttrain-mlogloss:0.585248\ttest-mlogloss:0.612783\n",
      "[36]\ttrain-mlogloss:0.582887\ttest-mlogloss:0.611024\n",
      "[37]\ttrain-mlogloss:0.580446\ttest-mlogloss:0.609263\n",
      "[38]\ttrain-mlogloss:0.578223\ttest-mlogloss:0.607794\n",
      "[39]\ttrain-mlogloss:0.576047\ttest-mlogloss:0.606283\n",
      "[40]\ttrain-mlogloss:0.573984\ttest-mlogloss:0.604831\n",
      "[41]\ttrain-mlogloss:0.572326\ttest-mlogloss:0.603701\n",
      "[42]\ttrain-mlogloss:0.569914\ttest-mlogloss:0.602112\n",
      "[43]\ttrain-mlogloss:0.568059\ttest-mlogloss:0.601128\n",
      "[44]\ttrain-mlogloss:0.566315\ttest-mlogloss:0.600132\n",
      "[45]\ttrain-mlogloss:0.564098\ttest-mlogloss:0.59887\n",
      "[46]\ttrain-mlogloss:0.561687\ttest-mlogloss:0.597403\n",
      "[47]\ttrain-mlogloss:0.559721\ttest-mlogloss:0.59618\n",
      "[48]\ttrain-mlogloss:0.557516\ttest-mlogloss:0.594945\n",
      "[49]\ttrain-mlogloss:0.556052\ttest-mlogloss:0.594073\n",
      "[50]\ttrain-mlogloss:0.55405\ttest-mlogloss:0.592778\n",
      "[51]\ttrain-mlogloss:0.552446\ttest-mlogloss:0.591762\n",
      "[52]\ttrain-mlogloss:0.550867\ttest-mlogloss:0.591072\n",
      "[53]\ttrain-mlogloss:0.549273\ttest-mlogloss:0.590349\n",
      "[54]\ttrain-mlogloss:0.547815\ttest-mlogloss:0.589504\n",
      "[55]\ttrain-mlogloss:0.545989\ttest-mlogloss:0.588721\n",
      "[56]\ttrain-mlogloss:0.544248\ttest-mlogloss:0.587825\n",
      "[57]\ttrain-mlogloss:0.542837\ttest-mlogloss:0.586998\n",
      "[58]\ttrain-mlogloss:0.541466\ttest-mlogloss:0.586218\n",
      "[59]\ttrain-mlogloss:0.53952\ttest-mlogloss:0.585247\n",
      "[60]\ttrain-mlogloss:0.537955\ttest-mlogloss:0.584324\n",
      "[61]\ttrain-mlogloss:0.536548\ttest-mlogloss:0.583609\n",
      "[62]\ttrain-mlogloss:0.535286\ttest-mlogloss:0.582945\n",
      "[63]\ttrain-mlogloss:0.534155\ttest-mlogloss:0.582601\n",
      "[64]\ttrain-mlogloss:0.532805\ttest-mlogloss:0.582244\n",
      "[65]\ttrain-mlogloss:0.532036\ttest-mlogloss:0.581786\n",
      "[66]\ttrain-mlogloss:0.530711\ttest-mlogloss:0.58118\n",
      "[67]\ttrain-mlogloss:0.529453\ttest-mlogloss:0.580549\n",
      "[68]\ttrain-mlogloss:0.527944\ttest-mlogloss:0.57989\n",
      "[69]\ttrain-mlogloss:0.526966\ttest-mlogloss:0.579489\n",
      "[70]\ttrain-mlogloss:0.525904\ttest-mlogloss:0.579121\n",
      "[71]\ttrain-mlogloss:0.524397\ttest-mlogloss:0.578704\n",
      "[72]\ttrain-mlogloss:0.522934\ttest-mlogloss:0.577837\n",
      "[73]\ttrain-mlogloss:0.521437\ttest-mlogloss:0.577314\n",
      "[74]\ttrain-mlogloss:0.520383\ttest-mlogloss:0.576909\n",
      "[75]\ttrain-mlogloss:0.51908\ttest-mlogloss:0.576358\n",
      "[76]\ttrain-mlogloss:0.517969\ttest-mlogloss:0.575787\n",
      "[77]\ttrain-mlogloss:0.516901\ttest-mlogloss:0.575431\n",
      "[78]\ttrain-mlogloss:0.515867\ttest-mlogloss:0.575139\n",
      "[79]\ttrain-mlogloss:0.514386\ttest-mlogloss:0.574472\n",
      "[80]\ttrain-mlogloss:0.513146\ttest-mlogloss:0.574088\n",
      "[81]\ttrain-mlogloss:0.511933\ttest-mlogloss:0.573778\n",
      "[82]\ttrain-mlogloss:0.510758\ttest-mlogloss:0.573414\n",
      "[83]\ttrain-mlogloss:0.509753\ttest-mlogloss:0.57296\n",
      "[84]\ttrain-mlogloss:0.508695\ttest-mlogloss:0.572684\n",
      "[85]\ttrain-mlogloss:0.507621\ttest-mlogloss:0.572458\n",
      "[86]\ttrain-mlogloss:0.506924\ttest-mlogloss:0.572193\n",
      "[87]\ttrain-mlogloss:0.505765\ttest-mlogloss:0.571699\n",
      "[88]\ttrain-mlogloss:0.504682\ttest-mlogloss:0.571351\n",
      "[89]\ttrain-mlogloss:0.503733\ttest-mlogloss:0.57125\n",
      "[90]\ttrain-mlogloss:0.502881\ttest-mlogloss:0.571026\n",
      "[91]\ttrain-mlogloss:0.501999\ttest-mlogloss:0.57077\n",
      "[92]\ttrain-mlogloss:0.501\ttest-mlogloss:0.570489\n",
      "[93]\ttrain-mlogloss:0.500051\ttest-mlogloss:0.570235\n",
      "[94]\ttrain-mlogloss:0.499359\ttest-mlogloss:0.57002\n",
      "[95]\ttrain-mlogloss:0.498119\ttest-mlogloss:0.569562\n",
      "[96]\ttrain-mlogloss:0.49754\ttest-mlogloss:0.569346\n",
      "[97]\ttrain-mlogloss:0.496673\ttest-mlogloss:0.569052\n",
      "[98]\ttrain-mlogloss:0.496004\ttest-mlogloss:0.568742\n",
      "[99]\ttrain-mlogloss:0.495053\ttest-mlogloss:0.568387\n",
      "[100]\ttrain-mlogloss:0.494545\ttest-mlogloss:0.568094\n",
      "[101]\ttrain-mlogloss:0.493997\ttest-mlogloss:0.56785\n",
      "[102]\ttrain-mlogloss:0.492982\ttest-mlogloss:0.567454\n",
      "[103]\ttrain-mlogloss:0.491988\ttest-mlogloss:0.567243\n",
      "[104]\ttrain-mlogloss:0.491271\ttest-mlogloss:0.56705\n",
      "[105]\ttrain-mlogloss:0.490384\ttest-mlogloss:0.566823\n",
      "[106]\ttrain-mlogloss:0.489787\ttest-mlogloss:0.56675\n",
      "[107]\ttrain-mlogloss:0.489169\ttest-mlogloss:0.566715\n",
      "[108]\ttrain-mlogloss:0.488248\ttest-mlogloss:0.566405\n",
      "[109]\ttrain-mlogloss:0.487406\ttest-mlogloss:0.566198\n",
      "[110]\ttrain-mlogloss:0.486319\ttest-mlogloss:0.5658\n",
      "[111]\ttrain-mlogloss:0.485622\ttest-mlogloss:0.565685\n",
      "[112]\ttrain-mlogloss:0.484798\ttest-mlogloss:0.565363\n",
      "[113]\ttrain-mlogloss:0.484163\ttest-mlogloss:0.565173\n",
      "[114]\ttrain-mlogloss:0.483401\ttest-mlogloss:0.564935\n",
      "[115]\ttrain-mlogloss:0.482716\ttest-mlogloss:0.564767\n",
      "[116]\ttrain-mlogloss:0.481681\ttest-mlogloss:0.564478\n",
      "[117]\ttrain-mlogloss:0.480965\ttest-mlogloss:0.564221\n",
      "[118]\ttrain-mlogloss:0.480108\ttest-mlogloss:0.564192\n",
      "[119]\ttrain-mlogloss:0.479411\ttest-mlogloss:0.563994\n",
      "[120]\ttrain-mlogloss:0.478656\ttest-mlogloss:0.563825\n",
      "[121]\ttrain-mlogloss:0.477781\ttest-mlogloss:0.563682\n",
      "[122]\ttrain-mlogloss:0.47694\ttest-mlogloss:0.563429\n",
      "[123]\ttrain-mlogloss:0.475875\ttest-mlogloss:0.563423\n",
      "[124]\ttrain-mlogloss:0.474901\ttest-mlogloss:0.563081\n",
      "[125]\ttrain-mlogloss:0.474137\ttest-mlogloss:0.563012\n",
      "[126]\ttrain-mlogloss:0.473332\ttest-mlogloss:0.562795\n",
      "[127]\ttrain-mlogloss:0.472544\ttest-mlogloss:0.562543\n",
      "[128]\ttrain-mlogloss:0.471945\ttest-mlogloss:0.562355\n",
      "[129]\ttrain-mlogloss:0.47132\ttest-mlogloss:0.562196\n",
      "[130]\ttrain-mlogloss:0.470594\ttest-mlogloss:0.562044\n",
      "[131]\ttrain-mlogloss:0.469755\ttest-mlogloss:0.561851\n",
      "[132]\ttrain-mlogloss:0.469016\ttest-mlogloss:0.561705\n",
      "[133]\ttrain-mlogloss:0.468292\ttest-mlogloss:0.561579\n",
      "[134]\ttrain-mlogloss:0.467752\ttest-mlogloss:0.561463\n",
      "[135]\ttrain-mlogloss:0.466966\ttest-mlogloss:0.561226\n",
      "[136]\ttrain-mlogloss:0.466374\ttest-mlogloss:0.561151\n",
      "[137]\ttrain-mlogloss:0.46564\ttest-mlogloss:0.560855\n",
      "[138]\ttrain-mlogloss:0.46492\ttest-mlogloss:0.560767\n",
      "[139]\ttrain-mlogloss:0.464143\ttest-mlogloss:0.560614\n",
      "[140]\ttrain-mlogloss:0.46344\ttest-mlogloss:0.560419\n",
      "[141]\ttrain-mlogloss:0.462586\ttest-mlogloss:0.560275\n",
      "[142]\ttrain-mlogloss:0.461938\ttest-mlogloss:0.560104\n",
      "[143]\ttrain-mlogloss:0.461007\ttest-mlogloss:0.560053\n",
      "[144]\ttrain-mlogloss:0.460229\ttest-mlogloss:0.559865\n",
      "[145]\ttrain-mlogloss:0.459635\ttest-mlogloss:0.55984\n",
      "[146]\ttrain-mlogloss:0.459237\ttest-mlogloss:0.559767\n",
      "[147]\ttrain-mlogloss:0.45856\ttest-mlogloss:0.559606\n",
      "[148]\ttrain-mlogloss:0.457896\ttest-mlogloss:0.559535\n",
      "[149]\ttrain-mlogloss:0.457168\ttest-mlogloss:0.559414\n",
      "[150]\ttrain-mlogloss:0.456344\ttest-mlogloss:0.559236\n",
      "[151]\ttrain-mlogloss:0.455722\ttest-mlogloss:0.559191\n",
      "[152]\ttrain-mlogloss:0.455007\ttest-mlogloss:0.559039\n",
      "[153]\ttrain-mlogloss:0.454369\ttest-mlogloss:0.55884\n",
      "[154]\ttrain-mlogloss:0.453453\ttest-mlogloss:0.558723\n",
      "[155]\ttrain-mlogloss:0.452651\ttest-mlogloss:0.558525\n",
      "[156]\ttrain-mlogloss:0.451813\ttest-mlogloss:0.558442\n",
      "[157]\ttrain-mlogloss:0.451055\ttest-mlogloss:0.558344\n",
      "[158]\ttrain-mlogloss:0.450309\ttest-mlogloss:0.558173\n",
      "[159]\ttrain-mlogloss:0.449685\ttest-mlogloss:0.558042\n",
      "[160]\ttrain-mlogloss:0.448884\ttest-mlogloss:0.557919\n",
      "[161]\ttrain-mlogloss:0.448265\ttest-mlogloss:0.557909\n",
      "[162]\ttrain-mlogloss:0.447685\ttest-mlogloss:0.557704\n",
      "[163]\ttrain-mlogloss:0.447103\ttest-mlogloss:0.557645\n",
      "[164]\ttrain-mlogloss:0.446614\ttest-mlogloss:0.557546\n",
      "[165]\ttrain-mlogloss:0.446064\ttest-mlogloss:0.55747\n",
      "[166]\ttrain-mlogloss:0.445366\ttest-mlogloss:0.557502\n",
      "[167]\ttrain-mlogloss:0.445047\ttest-mlogloss:0.557462\n",
      "[168]\ttrain-mlogloss:0.444401\ttest-mlogloss:0.557382\n",
      "[169]\ttrain-mlogloss:0.443826\ttest-mlogloss:0.557348\n",
      "[170]\ttrain-mlogloss:0.443218\ttest-mlogloss:0.557185\n",
      "[171]\ttrain-mlogloss:0.44266\ttest-mlogloss:0.557118\n",
      "[172]\ttrain-mlogloss:0.442048\ttest-mlogloss:0.557019\n",
      "[173]\ttrain-mlogloss:0.441554\ttest-mlogloss:0.556924\n",
      "[174]\ttrain-mlogloss:0.440769\ttest-mlogloss:0.556958\n",
      "[175]\ttrain-mlogloss:0.440161\ttest-mlogloss:0.556821\n",
      "[176]\ttrain-mlogloss:0.439691\ttest-mlogloss:0.556721\n",
      "[177]\ttrain-mlogloss:0.439132\ttest-mlogloss:0.556603\n",
      "[178]\ttrain-mlogloss:0.438422\ttest-mlogloss:0.556523\n",
      "[179]\ttrain-mlogloss:0.437599\ttest-mlogloss:0.556332\n",
      "[180]\ttrain-mlogloss:0.436936\ttest-mlogloss:0.556275\n",
      "[181]\ttrain-mlogloss:0.436404\ttest-mlogloss:0.556298\n",
      "[182]\ttrain-mlogloss:0.435684\ttest-mlogloss:0.556139\n",
      "[183]\ttrain-mlogloss:0.434982\ttest-mlogloss:0.555997\n",
      "[184]\ttrain-mlogloss:0.4345\ttest-mlogloss:0.555983\n",
      "[185]\ttrain-mlogloss:0.433853\ttest-mlogloss:0.555874\n",
      "[186]\ttrain-mlogloss:0.433313\ttest-mlogloss:0.555763\n",
      "[187]\ttrain-mlogloss:0.432787\ttest-mlogloss:0.555676\n",
      "[188]\ttrain-mlogloss:0.432276\ttest-mlogloss:0.555657\n",
      "[189]\ttrain-mlogloss:0.431945\ttest-mlogloss:0.555621\n",
      "[190]\ttrain-mlogloss:0.431664\ttest-mlogloss:0.555637\n",
      "[191]\ttrain-mlogloss:0.431226\ttest-mlogloss:0.555617\n",
      "[192]\ttrain-mlogloss:0.430683\ttest-mlogloss:0.555535\n",
      "[193]\ttrain-mlogloss:0.429923\ttest-mlogloss:0.555521\n",
      "[194]\ttrain-mlogloss:0.429244\ttest-mlogloss:0.555469\n",
      "[195]\ttrain-mlogloss:0.428674\ttest-mlogloss:0.55541\n",
      "[196]\ttrain-mlogloss:0.428067\ttest-mlogloss:0.555284\n",
      "[197]\ttrain-mlogloss:0.42754\ttest-mlogloss:0.555237\n",
      "[198]\ttrain-mlogloss:0.426881\ttest-mlogloss:0.555245\n",
      "[199]\ttrain-mlogloss:0.426407\ttest-mlogloss:0.555185\n",
      "[200]\ttrain-mlogloss:0.425852\ttest-mlogloss:0.555196\n",
      "[201]\ttrain-mlogloss:0.425391\ttest-mlogloss:0.555128\n",
      "[202]\ttrain-mlogloss:0.424889\ttest-mlogloss:0.555099\n",
      "[203]\ttrain-mlogloss:0.424417\ttest-mlogloss:0.555041\n",
      "[204]\ttrain-mlogloss:0.424002\ttest-mlogloss:0.555137\n",
      "[205]\ttrain-mlogloss:0.423398\ttest-mlogloss:0.555072\n",
      "[206]\ttrain-mlogloss:0.422696\ttest-mlogloss:0.554935\n",
      "[207]\ttrain-mlogloss:0.422317\ttest-mlogloss:0.554935\n",
      "[208]\ttrain-mlogloss:0.421671\ttest-mlogloss:0.554871\n",
      "[209]\ttrain-mlogloss:0.421198\ttest-mlogloss:0.554825\n",
      "[210]\ttrain-mlogloss:0.420686\ttest-mlogloss:0.554834\n",
      "[211]\ttrain-mlogloss:0.42021\ttest-mlogloss:0.554812\n",
      "[212]\ttrain-mlogloss:0.419537\ttest-mlogloss:0.554707\n",
      "[213]\ttrain-mlogloss:0.419064\ttest-mlogloss:0.554695\n",
      "[214]\ttrain-mlogloss:0.418403\ttest-mlogloss:0.554766\n",
      "[215]\ttrain-mlogloss:0.417821\ttest-mlogloss:0.554649\n",
      "[216]\ttrain-mlogloss:0.417208\ttest-mlogloss:0.554733\n",
      "[217]\ttrain-mlogloss:0.41678\ttest-mlogloss:0.554639\n",
      "[218]\ttrain-mlogloss:0.416123\ttest-mlogloss:0.554603\n",
      "[219]\ttrain-mlogloss:0.415532\ttest-mlogloss:0.554578\n",
      "[220]\ttrain-mlogloss:0.415263\ttest-mlogloss:0.554573\n",
      "[221]\ttrain-mlogloss:0.414763\ttest-mlogloss:0.554511\n",
      "[222]\ttrain-mlogloss:0.414192\ttest-mlogloss:0.554446\n",
      "[223]\ttrain-mlogloss:0.413608\ttest-mlogloss:0.554474\n",
      "[224]\ttrain-mlogloss:0.413125\ttest-mlogloss:0.554348\n",
      "[225]\ttrain-mlogloss:0.412664\ttest-mlogloss:0.554098\n",
      "[226]\ttrain-mlogloss:0.412141\ttest-mlogloss:0.554043\n",
      "[227]\ttrain-mlogloss:0.411716\ttest-mlogloss:0.553937\n",
      "[228]\ttrain-mlogloss:0.411276\ttest-mlogloss:0.553875\n",
      "[229]\ttrain-mlogloss:0.410817\ttest-mlogloss:0.553739\n",
      "[230]\ttrain-mlogloss:0.41042\ttest-mlogloss:0.553742\n",
      "[231]\ttrain-mlogloss:0.409902\ttest-mlogloss:0.553638\n",
      "[232]\ttrain-mlogloss:0.409453\ttest-mlogloss:0.55362\n",
      "[233]\ttrain-mlogloss:0.40903\ttest-mlogloss:0.553549\n",
      "[234]\ttrain-mlogloss:0.408491\ttest-mlogloss:0.553468\n",
      "[235]\ttrain-mlogloss:0.408081\ttest-mlogloss:0.553525\n",
      "[236]\ttrain-mlogloss:0.40768\ttest-mlogloss:0.553414\n",
      "[237]\ttrain-mlogloss:0.407038\ttest-mlogloss:0.553248\n",
      "[238]\ttrain-mlogloss:0.406504\ttest-mlogloss:0.553263\n",
      "[239]\ttrain-mlogloss:0.405949\ttest-mlogloss:0.553255\n",
      "[240]\ttrain-mlogloss:0.405377\ttest-mlogloss:0.553356\n",
      "[241]\ttrain-mlogloss:0.404728\ttest-mlogloss:0.553381\n",
      "[242]\ttrain-mlogloss:0.403946\ttest-mlogloss:0.55304\n",
      "[243]\ttrain-mlogloss:0.403491\ttest-mlogloss:0.552986\n",
      "[244]\ttrain-mlogloss:0.403053\ttest-mlogloss:0.552977\n",
      "[245]\ttrain-mlogloss:0.402516\ttest-mlogloss:0.553057\n",
      "[246]\ttrain-mlogloss:0.401916\ttest-mlogloss:0.553135\n",
      "[247]\ttrain-mlogloss:0.401368\ttest-mlogloss:0.553069\n",
      "[248]\ttrain-mlogloss:0.400757\ttest-mlogloss:0.55306\n",
      "[249]\ttrain-mlogloss:0.400323\ttest-mlogloss:0.553091\n",
      "[250]\ttrain-mlogloss:0.399869\ttest-mlogloss:0.553078\n",
      "[251]\ttrain-mlogloss:0.399422\ttest-mlogloss:0.553058\n",
      "[252]\ttrain-mlogloss:0.398792\ttest-mlogloss:0.553075\n",
      "[253]\ttrain-mlogloss:0.398204\ttest-mlogloss:0.553176\n",
      "[254]\ttrain-mlogloss:0.397772\ttest-mlogloss:0.55317\n",
      "[255]\ttrain-mlogloss:0.397513\ttest-mlogloss:0.553206\n",
      "[256]\ttrain-mlogloss:0.397002\ttest-mlogloss:0.553111\n",
      "[257]\ttrain-mlogloss:0.396493\ttest-mlogloss:0.553128\n",
      "[258]\ttrain-mlogloss:0.395928\ttest-mlogloss:0.553142\n",
      "[259]\ttrain-mlogloss:0.395403\ttest-mlogloss:0.55299\n",
      "[260]\ttrain-mlogloss:0.395152\ttest-mlogloss:0.553009\n",
      "[261]\ttrain-mlogloss:0.394542\ttest-mlogloss:0.552964\n",
      "[262]\ttrain-mlogloss:0.394097\ttest-mlogloss:0.552891\n",
      "[263]\ttrain-mlogloss:0.393452\ttest-mlogloss:0.552889\n",
      "[264]\ttrain-mlogloss:0.393101\ttest-mlogloss:0.552946\n",
      "[265]\ttrain-mlogloss:0.392661\ttest-mlogloss:0.552848\n",
      "[266]\ttrain-mlogloss:0.3922\ttest-mlogloss:0.552801\n",
      "[267]\ttrain-mlogloss:0.391733\ttest-mlogloss:0.552774\n",
      "[268]\ttrain-mlogloss:0.391062\ttest-mlogloss:0.55269\n",
      "[269]\ttrain-mlogloss:0.39042\ttest-mlogloss:0.552605\n",
      "[270]\ttrain-mlogloss:0.389996\ttest-mlogloss:0.55251\n",
      "[271]\ttrain-mlogloss:0.389715\ttest-mlogloss:0.552393\n",
      "[272]\ttrain-mlogloss:0.389269\ttest-mlogloss:0.552405\n",
      "[273]\ttrain-mlogloss:0.388747\ttest-mlogloss:0.55233\n",
      "[274]\ttrain-mlogloss:0.388255\ttest-mlogloss:0.55229\n",
      "[275]\ttrain-mlogloss:0.387832\ttest-mlogloss:0.552299\n",
      "[276]\ttrain-mlogloss:0.387402\ttest-mlogloss:0.552295\n",
      "[277]\ttrain-mlogloss:0.386913\ttest-mlogloss:0.55245\n",
      "[278]\ttrain-mlogloss:0.386623\ttest-mlogloss:0.552333\n",
      "[279]\ttrain-mlogloss:0.386185\ttest-mlogloss:0.552355\n",
      "[280]\ttrain-mlogloss:0.385689\ttest-mlogloss:0.552183\n",
      "[281]\ttrain-mlogloss:0.385494\ttest-mlogloss:0.552192\n",
      "[282]\ttrain-mlogloss:0.384969\ttest-mlogloss:0.552123\n",
      "[283]\ttrain-mlogloss:0.384429\ttest-mlogloss:0.551981\n",
      "[284]\ttrain-mlogloss:0.383798\ttest-mlogloss:0.552024\n",
      "[285]\ttrain-mlogloss:0.383478\ttest-mlogloss:0.552053\n",
      "[286]\ttrain-mlogloss:0.38293\ttest-mlogloss:0.552095\n",
      "[287]\ttrain-mlogloss:0.382323\ttest-mlogloss:0.552121\n",
      "[288]\ttrain-mlogloss:0.381906\ttest-mlogloss:0.552012\n",
      "[289]\ttrain-mlogloss:0.381329\ttest-mlogloss:0.552021\n",
      "[290]\ttrain-mlogloss:0.381056\ttest-mlogloss:0.551991\n",
      "[291]\ttrain-mlogloss:0.3805\ttest-mlogloss:0.552016\n",
      "[292]\ttrain-mlogloss:0.380059\ttest-mlogloss:0.552129\n",
      "[293]\ttrain-mlogloss:0.379516\ttest-mlogloss:0.552005\n",
      "[294]\ttrain-mlogloss:0.379164\ttest-mlogloss:0.552072\n",
      "[295]\ttrain-mlogloss:0.378658\ttest-mlogloss:0.551979\n",
      "[296]\ttrain-mlogloss:0.378212\ttest-mlogloss:0.551783\n",
      "[297]\ttrain-mlogloss:0.37774\ttest-mlogloss:0.551852\n",
      "[298]\ttrain-mlogloss:0.377169\ttest-mlogloss:0.55191\n",
      "[299]\ttrain-mlogloss:0.376519\ttest-mlogloss:0.551842\n",
      "[300]\ttrain-mlogloss:0.37601\ttest-mlogloss:0.551795\n",
      "[301]\ttrain-mlogloss:0.375521\ttest-mlogloss:0.551732\n",
      "[302]\ttrain-mlogloss:0.375081\ttest-mlogloss:0.551826\n",
      "[303]\ttrain-mlogloss:0.374733\ttest-mlogloss:0.551796\n",
      "[304]\ttrain-mlogloss:0.374241\ttest-mlogloss:0.551729\n",
      "[305]\ttrain-mlogloss:0.373901\ttest-mlogloss:0.551784\n",
      "[306]\ttrain-mlogloss:0.373342\ttest-mlogloss:0.551728\n",
      "[307]\ttrain-mlogloss:0.372874\ttest-mlogloss:0.551731\n",
      "[308]\ttrain-mlogloss:0.372487\ttest-mlogloss:0.551769\n",
      "[309]\ttrain-mlogloss:0.371904\ttest-mlogloss:0.551661\n",
      "[310]\ttrain-mlogloss:0.371271\ttest-mlogloss:0.551573\n",
      "[311]\ttrain-mlogloss:0.370917\ttest-mlogloss:0.551594\n",
      "[312]\ttrain-mlogloss:0.370575\ttest-mlogloss:0.551516\n",
      "[313]\ttrain-mlogloss:0.370015\ttest-mlogloss:0.551558\n",
      "[314]\ttrain-mlogloss:0.369665\ttest-mlogloss:0.551577\n",
      "[315]\ttrain-mlogloss:0.369306\ttest-mlogloss:0.551458\n",
      "[316]\ttrain-mlogloss:0.368777\ttest-mlogloss:0.551453\n",
      "[317]\ttrain-mlogloss:0.368369\ttest-mlogloss:0.551545\n",
      "[318]\ttrain-mlogloss:0.367907\ttest-mlogloss:0.551466\n",
      "[319]\ttrain-mlogloss:0.367532\ttest-mlogloss:0.551525\n",
      "[320]\ttrain-mlogloss:0.367136\ttest-mlogloss:0.551451\n",
      "[321]\ttrain-mlogloss:0.366453\ttest-mlogloss:0.551508\n",
      "[322]\ttrain-mlogloss:0.365978\ttest-mlogloss:0.551485\n",
      "[323]\ttrain-mlogloss:0.365566\ttest-mlogloss:0.551466\n",
      "[324]\ttrain-mlogloss:0.365135\ttest-mlogloss:0.551525\n",
      "[325]\ttrain-mlogloss:0.364663\ttest-mlogloss:0.551407\n",
      "[326]\ttrain-mlogloss:0.364082\ttest-mlogloss:0.551356\n",
      "[327]\ttrain-mlogloss:0.363717\ttest-mlogloss:0.551248\n",
      "[328]\ttrain-mlogloss:0.363358\ttest-mlogloss:0.551255\n",
      "[329]\ttrain-mlogloss:0.362893\ttest-mlogloss:0.551156\n",
      "[330]\ttrain-mlogloss:0.36241\ttest-mlogloss:0.551091\n",
      "[331]\ttrain-mlogloss:0.361977\ttest-mlogloss:0.551183\n",
      "[332]\ttrain-mlogloss:0.361618\ttest-mlogloss:0.551132\n",
      "[333]\ttrain-mlogloss:0.361149\ttest-mlogloss:0.551215\n",
      "[334]\ttrain-mlogloss:0.360792\ttest-mlogloss:0.551242\n",
      "[335]\ttrain-mlogloss:0.360313\ttest-mlogloss:0.551107\n",
      "[336]\ttrain-mlogloss:0.360046\ttest-mlogloss:0.551101\n",
      "[337]\ttrain-mlogloss:0.359626\ttest-mlogloss:0.551109\n",
      "[338]\ttrain-mlogloss:0.359218\ttest-mlogloss:0.551095\n",
      "[339]\ttrain-mlogloss:0.358781\ttest-mlogloss:0.551063\n",
      "[340]\ttrain-mlogloss:0.358417\ttest-mlogloss:0.551152\n",
      "[341]\ttrain-mlogloss:0.35794\ttest-mlogloss:0.55115\n",
      "[342]\ttrain-mlogloss:0.357678\ttest-mlogloss:0.551138\n",
      "[343]\ttrain-mlogloss:0.357154\ttest-mlogloss:0.551133\n",
      "[344]\ttrain-mlogloss:0.356827\ttest-mlogloss:0.551098\n",
      "[345]\ttrain-mlogloss:0.356486\ttest-mlogloss:0.551059\n",
      "[346]\ttrain-mlogloss:0.356026\ttest-mlogloss:0.551033\n",
      "[347]\ttrain-mlogloss:0.355777\ttest-mlogloss:0.551063\n",
      "[348]\ttrain-mlogloss:0.355316\ttest-mlogloss:0.551115\n",
      "[349]\ttrain-mlogloss:0.35493\ttest-mlogloss:0.551173\n",
      "[350]\ttrain-mlogloss:0.354528\ttest-mlogloss:0.551154\n",
      "[351]\ttrain-mlogloss:0.35418\ttest-mlogloss:0.551084\n",
      "[352]\ttrain-mlogloss:0.353656\ttest-mlogloss:0.551163\n",
      "[353]\ttrain-mlogloss:0.353276\ttest-mlogloss:0.551178\n",
      "[354]\ttrain-mlogloss:0.352867\ttest-mlogloss:0.551221\n",
      "[355]\ttrain-mlogloss:0.352427\ttest-mlogloss:0.551206\n",
      "[356]\ttrain-mlogloss:0.352037\ttest-mlogloss:0.551199\n",
      "[357]\ttrain-mlogloss:0.351628\ttest-mlogloss:0.551148\n",
      "[358]\ttrain-mlogloss:0.351246\ttest-mlogloss:0.551084\n",
      "[359]\ttrain-mlogloss:0.351037\ttest-mlogloss:0.551156\n",
      "[360]\ttrain-mlogloss:0.350729\ttest-mlogloss:0.551125\n",
      "[361]\ttrain-mlogloss:0.350321\ttest-mlogloss:0.551157\n",
      "[362]\ttrain-mlogloss:0.349892\ttest-mlogloss:0.551161\n",
      "[363]\ttrain-mlogloss:0.349404\ttest-mlogloss:0.551176\n",
      "[364]\ttrain-mlogloss:0.349087\ttest-mlogloss:0.55109\n",
      "[365]\ttrain-mlogloss:0.348569\ttest-mlogloss:0.551107\n",
      "[366]\ttrain-mlogloss:0.34816\ttest-mlogloss:0.551039\n",
      "Stopping. Best iteration:\n",
      "[346]\ttrain-mlogloss:0.356026\ttest-mlogloss:0.551033\n",
      "\n",
      "[0.55103850039735747]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    #kf.split(range(train_X.shape[0])):\n",
    "        dev_X, val_X = train_X[dev_index], train_X[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49352x217 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1093045 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54990436153530886"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=xgbClass(eta=.1, colsample_bytree=.7, eva_metric=\"mlogloss\", subsample=.7, max_depth=6, silent=1, seed=0, \\\n",
    "               num_class=3, objective='multi:softprob')\n",
    "CVScore(model=model, my_score=log_loss, X_train=train_X, y_train=train_y, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let us build the final model and get the predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=400)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_starter2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "Hope this helps the python users as a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imp=pd.DataFrame()#(index=features_to_use)\n",
    "imp['train'] = pd.Series(model.get_score(importance_type='gain'))#, index=features_to_use)\n",
    "imp = imp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEICAYAAAAzydF1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlitObGZmlitObGZmliv/H4zAlU1FZNsBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cd8f850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=imp.sort_values('train').tail(10).plot.barh(title='Feature importances sorted by train', figsize=(7,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
